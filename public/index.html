<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio Translator</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 0;
        }

        .container {
            /* max-width: 1200px; */
            margin: 0 auto;
            background: white;
            /* border-radius: 20px; */
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            display: none;
        }

        .controls {
            padding: 1rem 2rem;
            /* border-bottom: 1px solid #eee; */
            display: flex;
            justify-content: space-around;
            /* justify-content: space-between; */
            align-items: center;
        }

        .language-selector {
            display: none;
            align-items: center;
            gap: 10px;
        }

        .language-selector label {
            font-weight: 600;
            color: #333;
            white-space: nowrap;
            min-width: auto;
        }

        .language-selector select {
            padding: 8px 16px;
            border-radius: 16px;
            border: 1px solid #ccc;
            font-size: 14px;
            background: white;
        }

        .recording-controls {
            display: flex;
            gap: 15px;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .btn-primary {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.3);
        }

        .btn-danger {
            background: linear-gradient(45deg, #ff6b6b, #ee5a52);
            color: white;
        }

        .btn-danger:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(255, 107, 107, 0.3);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none !important;
        }

        .status {
            text-align: center;
            padding: 1rem;
            font-weight: 600;
        }

        .status.recording {
            color: #ee5a52;
            animation: pulse 1.5s infinite;
        }

        .status.connected {
            color: #51cf66;
        }

        .status.disconnected {
            color: #ff6b6b;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .translations {
            padding: 1rem 2rem;
            min-height: calc(100vh - 20px);
        }

        #translationsList {
            height: 80vh;
            padding-bottom: 1vh;
            overflow-y: auto;
        }

        .translation-item {
            background: #f8f9fa;
            /* border-left: 4px solid #667eea; */
            animation: fadeIn 0.5s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .timestamp {
            font-size: 0.8rem;
            color: #999;
            margin-bottom: 15px;
        }

        .source-text {
            display: none;
        }

        #label-container {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
            background-color: #f8f9fa;
            /* margin-left: 4px; */

        }

        .translations-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
        }

        .translation {
            background: white;
            padding: 10px 20px;
            /* box-shadow: 0 4px 15px rgba(0,0,0,0.1); */
            border-left: 2px solid #f0f0f0;
            transition: all 0.3s ease;
        }

        .translation-label {
            font-size: 1.5rem;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 10px;
            text-transform: uppercase;
            text-align: center;
            padding:10px 20px;
            background:white;
            border: 1px solid #ccc;
            /* box-shadow: 0 4px 15px rgba(0,0,0,0.1); */
            
        }

        .translation-text {
            font-size: 2.6rem;
            color: #333;
            line-height: 1.6;
            font-weight: 500;
        }

        .source-info {
            text-align: center;
            padding: 10px;
            font-size: 0.9rem;
            color: #666;
            font-style: italic;
            border-top: 1px solid #eee;
            margin-top: 15px;
        }

        .empty-state {
            text-align: center;
            color: #999;
            font-style: italic;
            padding: 60px 20px;
        }

        .error {
            background: #ffe0e0;
            color: #d63031;
            border-left-color: #d63031;
        }

        .file-upload {
            margin-top: 20px;
            padding: 20px;
            border: 2px dashed #ddd;
            border-radius: 10px;
            text-align: center;
            background: #fafafa;
        }

        .file-upload input[type="file"] {
            margin: 10px 0;
        }

        @media (max-width: 768px) {
            .btn {
                width: 100%;
                justify-content: center;
            }
        }

        @media (max-width: 500px) {
            .translation-label {
                font-size: 0.85rem;
                padding: 8px;
            }
            .translations {
                padding: 10px;
            }
            .controls {
                padding: 10px;
            }
            .btn {
                padding: 0.8rem 1rem;
                font-size: 15px;
                width: 45vw;
            }
            .recording-controls {
                flex-direction: row;
            }
            .translation {
                padding:5px;
            }
            .translation-text {
                font-size: 1rem;
            }
            .translations-grid {
                gap:10px;
                grid-template-columns: 1fr 1fr;
            }
            #label-container {
                gap: 10px;
                grid-template-columns: 1fr 1fr;
            }
            .translation-label:nth-child(3),.translation:nth-child(3) {
                display: none;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="controls">
            <div class="recording-controls">
                <button id="startBtn" class="btn btn-primary">
                    üé§ Start Recording
                </button>
                <button id="stopBtn" class="btn btn-danger" disabled>
                    ‚èπÔ∏è Stop Recording
                </button>
            </div>
            <div class="language-selector">
                <label for="sourceLanguage">Language:</label>
                <select id="sourceLanguage">
                    <option value="auto">Auto-detect</option>
                    <option value="en">English</option>
                    <option value="it">Italiano</option>
                    <option value="zh">‰∏≠Êñá</option>
                </select>
            </div>

            
        </div>

        <div id="status" class="status">Ready to translate</div>

        <div class="translations">
            <div id="label-container">
                <div class="translation-label">üáÆüáπ Italiano</div>
                <div class="translation-label">üá®üá≥ ‰∏≠Êñá</div>
                <div class="translation-label">üá∫üá∏ English</div>
            </div>

            <div id="translationsList">
                <div class="empty-state">
                    <!-- Start recording to see translations in Italian, Chinese, and English appear here -->
                </div>
            </div>
        </div>
    </div>

    <script>
        // ==============================================
        // CONFIGURABLE AUDIO CHUNKING PARAMETERS
        // ==============================================
        const AUDIO_CONFIG = {
            MAX_CHUNK_DURATION: 6000,    // Maximum chunk length in milliseconds (6 seconds)
            SILENCE_THRESHOLD: 700,      // Silence duration to trigger chunk in milliseconds (700ms) - INCREASED
            VOLUME_THRESHOLD: 10,        // Audio level threshold (0-255, higher = louder sounds required) - MUCH HIGHER
            MIN_CHUNK_DURATION: 1000,    // Minimum chunk duration before silence detection kicks in (1 second)
            
            // Audio content detection thresholds
            MIN_AVERAGE_VOLUME: 0.008,    // Minimum average audio level (0-1)
            MIN_PEAK_VOLUME: 0.08,       // Minimum peak audio level (0-1)
            MIN_ACTIVE_SAMPLES: 2.0      // Minimum percentage of samples above noise floor
        };
        // ==============================================

        const isMobile = function(){
            return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        }   

        class AudioTranslator {
            constructor() {
                this.ws = null;
                this.mediaRecorder = null;
                this.audioStream = null;
                this.isRecording = false;
                this.audioChunks = [];
                this.silenceDetectionInterval = null;
                this.lastAudioTime = 0;
                this.maxChunkDuration = AUDIO_CONFIG.MAX_CHUNK_DURATION;
                this.silenceThreshold = AUDIO_CONFIG.SILENCE_THRESHOLD;
                this.volumeThreshold = AUDIO_CONFIG.VOLUME_THRESHOLD;
                this.minChunkDuration = AUDIO_CONFIG.MIN_CHUNK_DURATION;
                this.chunkStartTime = 0;
                
                this.initializeElements();
                this.setupEventListeners();
                this.connectWebSocket();
            }

            initializeElements() {
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.status = document.getElementById('status');
                this.sourceLanguageSelect = document.getElementById('sourceLanguage');
                this.translationsList = document.getElementById('translationsList');
            }

            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.startRecording());
                this.stopBtn.addEventListener('click', () => this.stopRecording());
            }

            connectWebSocket() {
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                this.ws = new WebSocket(protocol + '//' + window.location.host);

                this.ws.onopen = () => {
                    this.updateStatus('Connected', 'connected');
                };

                this.ws.onclose = () => {
                    this.updateStatus('Disconnected - Reconnecting...', 'disconnected');
                    setTimeout(() => this.connectWebSocket(), 3000);
                };

                this.ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    this.handleWebSocketMessage(data);
                };
            }

            handleWebSocketMessage(data) {
                if (data.type === 'translation_result') {
                    this.displayTranslation(data);
                } else if (data.type === 'error') {
                    this.displayError(data.message);
                }
            }

            async startRecording() {
                try {
                    this.audioStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.mediaRecorder = new MediaRecorder(this.audioStream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    this.audioChunks = [];
                    this.chunkStartTime = Date.now();
                    this.lastAudioTime = Date.now();

                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                    };

                    this.mediaRecorder.onstop = () => {
                        this.processAudioChunks();
                    };

                    // Start recording in continuous mode
                    this.mediaRecorder.start(100); // Small timeslices for real-time analysis

                    // Set up real-time audio analysis for silence detection
                    this.setupSilenceDetection();

                    this.isRecording = true;
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;
                    this.updateStatus('Recording...', 'recording');

                } catch (error) {
                    console.error('Error starting recording:', error);
                    this.displayError('Failed to access microphone');
                }
            }

            setupSilenceDetection() {
                // Create audio context for real-time analysis
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                this.analyser = this.audioContext.createAnalyser();
                this.analyser.fftSize = 2048;
                
                const source = this.audioContext.createMediaStreamSource(this.audioStream);
                source.connect(this.analyser);
                
                const bufferLength = this.analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Monitor audio levels continuously
                this.silenceDetectionInterval = setInterval(() => {
                    if (!this.isRecording) return;
                    
                    this.analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const averageVolume = sum / bufferLength;
                    
                    const currentTime = Date.now();
                    const chunkDuration = currentTime - this.chunkStartTime;
                    
                    // Check if we have audio activity
                    if (averageVolume > this.volumeThreshold) {
                        this.lastAudioTime = currentTime;
                    }
                    
                    const silenceDuration = currentTime - this.lastAudioTime;
                    
                    // Trigger chunk processing if:
                    // 1. We've had silence for more than threshold AND we have some audio data
                    // 2. OR we've reached the maximum chunk duration
                    if ((silenceDuration > this.silenceThreshold && chunkDuration > this.minChunkDuration) || 
                        chunkDuration > this.maxChunkDuration) {
                        
                        console.log(`Chunking: silence=${silenceDuration}ms, duration=${chunkDuration}ms, avgVol=${averageVolume.toFixed(1)}`);
                        this.triggerChunkProcessing();
                    }
                }, 50); // Check every 50ms
            }

            triggerChunkProcessing() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    // Stop current recording to process the chunk
                    this.mediaRecorder.stop();
                    
                    // Restart recording for next chunk
                    setTimeout(() => {
                        if (this.isRecording) {
                            this.mediaRecorder.start(100);
                            this.chunkStartTime = Date.now();
                            this.lastAudioTime = Date.now();
                        }
                    }, 10);
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    clearInterval(this.silenceDetectionInterval);
                    
                    this.mediaRecorder.stop();
                    this.audioStream.getTracks().forEach(track => track.stop());
                    
                    if (this.audioContext) {
                        this.audioContext.close();
                    }
                    
                    this.isRecording = false;
                    this.startBtn.disabled = false;
                    this.stopBtn.disabled = true;
                    this.updateStatus('Processing...', 'connected');
                }
            }

            async processAudioChunks() {
                if (this.audioChunks.length === 0) return;

                try {
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    
                    console.log('üîç Analyzing audio content before API call...');
                    
                    // Check if audio has sufficient volume before sending to API
                    if (!(await this.hasAudioContent(audioBlob))) {
                        console.log('üîá No significant audio detected, SKIPPING Whisper API call - saving costs!');
                        this.audioChunks = [];
                        
                        if (this.isRecording) {
                            this.updateStatus('Recording...', 'recording');
                        } else {
                            this.updateStatus('Connected', 'connected');
                        }
                        return;
                    }
                    
                    console.log('üéµ Audio content detected, proceeding with Whisper API call');
                    
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

                    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                        console.log('üì§ Sending audio to server for Whisper processing...');
                        this.ws.send(JSON.stringify({
                            type: 'audio_chunk',
                            audio: base64Audio,
                            sourceLanguage: this.sourceLanguageSelect.value
                        }));
                    }

                    this.audioChunks = [];
                    
                    if (this.isRecording) {
                        this.updateStatus('Recording...', 'recording');
                    } else {
                        this.updateStatus('Connected', 'connected');
                    }

                } catch (error) {
                    console.error('Error processing audio:', error);
                    this.displayError('Failed to process audio');
                }
            }

            // Check if audio blob contains significant audio content
            async hasAudioContent(audioBlob) {
                // Skip complex analysis on mobile - just check blob size
                if (isMobile){
                    if (audioBlob.size < 1000) { // Less than 1KB is likely empty
                        console.log('Audio blob too small:', audioBlob.size);
                        return false;
                    }
                    return true; // Accept all non-tiny audio blobs on mobile
                }
    
                return new Promise((resolve) => {
                    try {
                        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const fileReader = new FileReader();
                        
                        fileReader.onload = async (e) => {
                            try {
                                const arrayBuffer = e.target.result;
                                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                                
                                // Analyze audio data for actual speech content
                                const channelData = audioBuffer.getChannelData(0);
                                const sampleRate = audioBuffer.sampleRate;
                                const duration = audioBuffer.duration;
                                
                                // Calculate various audio metrics
                                let sum = 0;
                                let maxVolume = 0;
                                let samplesAboveNoise = 0;
                                let energySum = 0;
                                
                                const noiseFloor = 0.01; // Noise floor threshold
                                const speechThreshold = 0.05; // Threshold for potential speech
                                
                                for (let i = 0; i < channelData.length; i++) {
                                    const sample = Math.abs(channelData[i]);
                                    sum += sample;
                                    energySum += sample * sample; // Energy calculation
                                    maxVolume = Math.max(maxVolume, sample);
                                    
                                    if (sample > noiseFloor) {
                                        samplesAboveNoise++;
                                    }
                                }
                                
                                const averageVolume = sum / channelData.length;
                                const rmsVolume = Math.sqrt(energySum / channelData.length); // RMS for better speech detection
                                const percentageAboveNoise = (samplesAboveNoise / channelData.length) * 100;
                                
                                // Calculate dynamic range (difference between loudest and average)
                                const dynamicRange = maxVolume - averageVolume;
                                
                                // Multi-criteria check for actual speech content
                                const hasSignificantVolume = averageVolume > AUDIO_CONFIG.MIN_AVERAGE_VOLUME;
                                const hasPeakVolume = maxVolume > AUDIO_CONFIG.MIN_PEAK_VOLUME;
                                const hasActiveContent = percentageAboveNoise > AUDIO_CONFIG.MIN_ACTIVE_SAMPLES;
                                const hasSpeechCharacteristics = rmsVolume > 0.015 && dynamicRange > 0.01;
                                const hasMinimumDuration = duration > 0.5; // At least half a second of audio
                                
                                // Require multiple criteria to be met
                                const passedCriteria = [hasSignificantVolume, hasPeakVolume, hasActiveContent, hasSpeechCharacteristics, hasMinimumDuration].filter(Boolean).length;
                                const hasContent = (passedCriteria == 5);//passedCriteria >= 3;
                                
                                // Log detailed analysis when content is REJECTED
                                if (!hasContent) {
                                    console.log("hasSignificantVolume:", hasSignificantVolume, 
                                    'hasPeakVolume: ', hasPeakVolume, 
                                    "hasActiveContent: ", hasActiveContent, 
                                    "hasSpeechCharacteristics:",hasSpeechCharacteristics,
                                    "hasMinimumDuration:", hasMinimumDuration)
                                }
                                
                                audioContext.close();
                                resolve(hasContent);
                            } catch (error) {
                                console.log('üö´ Audio analysis FAILED - Rejecting to prevent hallucination:', error.message);
                                resolve(false);
                            }
                        };
                        
                        fileReader.onerror = () => {
                            console.log('üö´ FileReader ERROR - Rejecting to prevent hallucination');
                            resolve(false);
                        };
                        
                        fileReader.readAsArrayBuffer(audioBlob);
                    } catch (error) {
                        console.log('üö´ Audio context FAILED - Rejecting to prevent hallucination:', error.message);
                        resolve(false);
                    }
                });
            }

            async uploadFile() {
                // File upload functionality removed
            }

            displayTranslation(data) {
                const translationsContainer = this.translationsList;
                
                // Remove empty state if present
                const emptyState = translationsContainer.querySelector('.empty-state');
                if (emptyState) {
                    emptyState.remove();
                }

                const translationItem = document.createElement('div');
                translationItem.className = 'translation-item';
                
                const timestamp = new Date(data.timestamp).toLocaleTimeString();
                const languageNames = { 
                    'en': 'English', 
                    'it': 'Italian', 
                    'zh': 'Chinese',
                    'zh-cn': 'Chinese',
                    'zh-CN': 'Chinese',
                    'zh-tw': 'Chinese',
                    'zh-TW': 'Chinese',
                    'auto': 'Auto-detected'
                };
                
                const detectedLangName = languageNames[data.sourceLanguage] || data.sourceLanguage.toUpperCase();
                
                translationItem.innerHTML = 
                    '<div class="translations-grid">' +
                        '<div class="translation">' +
                            // '<div class="translation-label">üáÆüáπ Italiano</div>' +
                            '<div class="translation-text">' + (data.translations.it || 'N/A') + '</div>' +
                        '</div>' +
                        '<div class="translation">' +
                            // '<div class="translation-label">üá®üá≥ ‰∏≠Êñá</div>' +
                            '<div class="translation-text">' + (data.translations.zh || 'N/A') + '</div>' +
                        '</div>' +
                        '<div class="translation">' +
                            // '<div class="translation-label">üá∫üá∏ English</div>' +
                            '<div class="translation-text">' + (data.translations.en || 'N/A') + '</div>' +
                        '</div>' +
                    '</div>' 
                    // +
                    // '<div class="source-info">' +
                    //     '<span>Source (' + detectedLangName + '): ' + data.sourceText + '</span>' +
                    //     '<span class="timestamp">' + timestamp + '</span>' +
                    // '</div>';
                translationsContainer.appendChild(translationItem)
                
                function scrollToBottom(container) {
                    container.scrollTo({
                        top: container.scrollHeight,
                        behavior: 'smooth'
                    });
                }

                scrollToBottom(translationsContainer);


                // translationsContainer.insertBefore(translationItem, translationsContainer.firstChild);
                
                // Keep only last 20 translations
                const items = translationsContainer.querySelectorAll('.translation-item');
                // if (items.length > 20) {
                //     items[items.length - 1].remove();
                // }
            }

            displayError(message) {
                const translationsContainer = this.translationsList;
                
                const errorItem = document.createElement('div');
                errorItem.className = 'translation-item error';
                errorItem.innerHTML = 
                    '<div class="timestamp">' + new Date().toLocaleTimeString() + '</div>' +
                    '<div class="source-text">Error: ' + message + '</div>';
                
                translationsContainer.insertBefore(errorItem, translationsContainer.firstChild);
            }

            updateStatus(message, className) {
                this.status.textContent = message;
                this.status.className = 'status ' + className;
            }
        }

        // Initialize the app when page loads
        document.addEventListener('DOMContentLoaded', () => {
            new AudioTranslator();
        });

    </script>
</body>
</html>